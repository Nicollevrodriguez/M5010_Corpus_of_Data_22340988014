{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f908006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: jupyterlab in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (3.6.3)\n",
      "Requirement already satisfied: ipywidgets>=7.5 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (8.0.4)\n",
      "Requirement already satisfied: ipython in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (8.15.0)\n",
      "Requirement already satisfied: packaging in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (23.1)\n",
      "Requirement already satisfied: tornado>=6.1.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (6.3.2)\n",
      "Requirement already satisfied: jupyter-core in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-server~=2.19 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (2.22.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (1.23.4)\n",
      "Requirement already satisfied: jupyter-ydoc~=0.2.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: jupyter-server-ydoc~=0.8.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: nbclassic in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (0.5.5)\n",
      "Requirement already satisfied: notebook<7 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (6.5.4)\n",
      "Requirement already satisfied: jinja2>=2.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab) (3.1.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipywidgets>=7.5) (6.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipywidgets>=7.5) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipywidgets>=7.5) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipywidgets>=7.5) (3.0.5)\n",
      "Requirement already satisfied: appnope in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (0.1.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (1.5.6)\n",
      "Requirement already satisfied: psutil in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5) (23.2.0)\n",
      "Requirement already satisfied: backcall in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ipython->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jinja2>=2.1->jupyterlab) (2.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-core->jupyterlab) (3.10.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (3.5.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (6.5.4)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.9.2)\n",
      "Requirement already satisfied: prometheus-client in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: Send2Trash in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.58.0)\n",
      "Requirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.9.0)\n",
      "Requirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.8.2)\n",
      "Requirement already satisfied: y-py<0.6.0,>=0.5.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-ydoc~=0.2.3->jupyterlab) (0.5.9)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab-server~=2.19->jupyterlab) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab-server~=2.19->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab-server~=2.19->jupyterlab) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyterlab-server~=2.19->jupyterlab) (2.31.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from notebook<7->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbclassic->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from babel>=2.10->jupyterlab-server~=2.19->jupyterlab) (2023.3.post1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (0.18.0)\n",
      "Requirement already satisfied: entrypoints in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.5) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.5) (2.8.2)\n",
      "Requirement already satisfied: jupyter-events>=0.5.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: lxml in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.9.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: bleach in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from nbformat>=5.2.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (2024.2.2)\n",
      "Requirement already satisfied: aiofiles<23,>=22.1.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (22.1.0)\n",
      "Requirement already satisfied: aiosqlite<1,>=0.17.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.18.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: executing in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from websocket-client->jupyter-server<3,>=1.16.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (2.4)\n",
      "Requirement already satisfied: webencodings in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (2.21)\n",
      "Requirement already satisfied: fqdn in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (2.1)\n",
      "Requirement already satisfied: uri-template in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/nicolerodriguezq/anaconda3/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (1.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nicolerodriguezq/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Uploading relevant libraries \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "!pip install plotly\n",
    "from IPython.display import IFrame\n",
    "import scipy as sp\n",
    "import plotly.express as px\n",
    "!pip install jupyterlab \"ipywidgets>=7.5\"\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import stem\n",
    "stemmer = stem.PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punct = list(string.punctuation)\n",
    "from collections import Counter\n",
    "import requests\n",
    "import numpy as np\n",
    "import praw \n",
    "import datetime\n",
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366cb593",
   "metadata": {},
   "source": [
    "# About This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1014963",
   "metadata": {},
   "source": [
    "## Corpus of Data: Reddit's Top Upvoted Stories\n",
    "This notebook shows the collection, cleaning and preprocessing of corpus of data from the Subreddit **‘Stories’**, a top 1% community in Reddit. I gathered the top 10 stories of all time, alongside the comments made to each post, aiming to have a ready-to-use linguistic dataset for future NLP (Natural Language Processing) analysis of narratives, storytelling, and public engagement.\n",
    "\n",
    "#### NLP\n",
    "\n",
    "It’s the use of linguistics, statistics and machine learning through computational modelling, that allows us to study insights on various aspects of human languages, such as (but not limited to) interactions, emotions, and machine translation (Joshi, 1991).\n",
    "\n",
    "#### What Makes a Good Story?\n",
    "\n",
    "Specifically, I aim to explore the the linguistic characteristics of highly upvoted and commented stories, along with the emotional dimensions of both the narratives and the people who engage with them. \n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fdb08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading datasets to index later.\n",
    "vad = pd.read_excel('vad.xlsx', index_col =0)\n",
    "sm = pd.read_excel('sensorimotor.xlsx', index_col =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd04394",
   "metadata": {},
   "source": [
    "### API (Application Programming Interface)\n",
    "\n",
    "To gather all the reddit posts, I used APIs - specific functions that allows a one way ‘transaction’ within two applications (Frye, 2018), in this case me, in this notebook, and Reddit. The APIs allowed me to extract the stories and their metadata directly to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f467e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit set-up\n",
    "reddit = praw.Reddit(user_agent='VAD',\n",
    "                    client_id='6K4b0HkPXk1fmP7kDc1-gQ', client_secret= \"Jux1YRp1VJwHzb8yZC-X0lr9QwOBFg\",\n",
    "                    username= 'NicolleVR', password= '/dk@4^u#Tw%J65:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93edeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract specific data needed\n",
    "def submission(submission_id):\n",
    "    try:\n",
    "        submission = reddit.submission(url=submission_id)\n",
    "    except:\n",
    "        submission = reddit.submission(submission_id)\n",
    "\n",
    "    # Extracting main post details\n",
    "    main_post = {\n",
    "        'text': submission.selftext,\n",
    "        'datetime': datetime.datetime.fromtimestamp(submission.created_utc),\n",
    "        'score': submission.score,\n",
    "        'subreddit': submission.subreddit,\n",
    "        'redditor': submission.author,\n",
    "        'type': 'submission',\n",
    "        'title': submission.title\n",
    "    }\n",
    "\n",
    "    # Extracting comments details\n",
    "    submission.comments.replace_more()\n",
    "    comments = []\n",
    "    for comment in submission.comments.list():\n",
    "        comment_data = {\n",
    "            'text': comment.body,\n",
    "            'datetime': datetime.datetime.fromtimestamp(comment.created_utc),\n",
    "            'score': comment.score,\n",
    "            'subreddit': submission.subreddit,\n",
    "            'redditor': comment.author,\n",
    "            'type': 'comment',\n",
    "            'title': submission.title\n",
    "        }\n",
    "        comments.append(comment_data)\n",
    "\n",
    "    # Concatenate main post and comments into a DataFrame\n",
    "    df = pd.DataFrame([main_post] + comments)\n",
    "\n",
    "    # Sorting DataFrame by score\n",
    "    df = df.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb57df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the code works with the first top story.\n",
    "story_1 = submission('https://www.reddit.com/r/stories/comments/16vqxs6/i_thought_she_took_me_to_the_restroom_to_have_sex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d662f7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In college I met a girl at a house party. We d...</td>\n",
       "      <td>2023-09-30 00:25:52</td>\n",
       "      <td>37468</td>\n",
       "      <td>stories</td>\n",
       "      <td>CardiffGiant1212</td>\n",
       "      <td>submission</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dude, I hate to break it to you but as soon as...</td>\n",
       "      <td>2023-09-30 01:34:12</td>\n",
       "      <td>1779</td>\n",
       "      <td>stories</td>\n",
       "      <td>stpg1222</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coward</td>\n",
       "      <td>2023-09-30 00:38:37</td>\n",
       "      <td>1226</td>\n",
       "      <td>stories</td>\n",
       "      <td>Tall-Remote3112</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lmao I asked my husband what he would do if th...</td>\n",
       "      <td>2023-09-30 02:13:34</td>\n",
       "      <td>1055</td>\n",
       "      <td>stories</td>\n",
       "      <td>Jilltro</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everyone knows the order is drinking, talking,...</td>\n",
       "      <td>2023-09-30 01:24:44</td>\n",
       "      <td>715</td>\n",
       "      <td>stories</td>\n",
       "      <td>oldmanartie</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            datetime  \\\n",
       "0  In college I met a girl at a house party. We d... 2023-09-30 00:25:52   \n",
       "1  Dude, I hate to break it to you but as soon as... 2023-09-30 01:34:12   \n",
       "2                                             Coward 2023-09-30 00:38:37   \n",
       "3  Lmao I asked my husband what he would do if th... 2023-09-30 02:13:34   \n",
       "4  Everyone knows the order is drinking, talking,... 2023-09-30 01:24:44   \n",
       "\n",
       "   score subreddit          redditor        type  \\\n",
       "0  37468   stories  CardiffGiant1212  submission   \n",
       "1   1779   stories          stpg1222     comment   \n",
       "2   1226   stories   Tall-Remote3112     comment   \n",
       "3   1055   stories           Jilltro     comment   \n",
       "4    715   stories       oldmanartie     comment   \n",
       "\n",
       "                                               title  \n",
       "0  I thought she took me to the restroom to have ...  \n",
       "1  I thought she took me to the restroom to have ...  \n",
       "2  I thought she took me to the restroom to have ...  \n",
       "3  I thought she took me to the restroom to have ...  \n",
       "4  I thought she took me to the restroom to have ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f50a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the other 9 top stories (most upvoted stories)\n",
    "story_2 = submission('https://www.reddit.com/r/stories/comments/15ysuej/i32m_am_divorcing_my_wife_33f_after_finding_out/')\n",
    "story_3 = submission('https://www.reddit.com/r/stories/comments/1612ts0/my_sister_died_during_postpartum_and_im_a/')\n",
    "story_4 = submission('https://www.reddit.com/r/stories/comments/15skbuq/i_surprised_my_girlfriend_with_taylor_swift/')\n",
    "story_5 = submission('https://www.reddit.com/r/stories/comments/16ezv93/i_accidentally_shit_the_bed_in_front_of_my/')\n",
    "story_6 = submission('https://www.reddit.com/r/stories/comments/18d8tvj/my_girlfriend_confessed_to_cheating_on_me_so_i/')\n",
    "story_7 = submission('https://www.reddit.com/r/stories/comments/17gkyty/a_quick_story_about_my_dating_policy_for_my/')\n",
    "story_8 = submission('https://www.reddit.com/r/stories/comments/16piw5d/four_days_ago_my_coworker_whos_also_my_friend/')\n",
    "story_9 = submission('https://www.reddit.com/r/stories/comments/1837bm4/my_boyfriend_turned_me_bi/')\n",
    "story_10 = submission('https://www.reddit.com/r/stories/comments/15gzmzb/husband_wants_to_reset_his_whole_life/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7e8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a single dataset out of all stories. \n",
    "all_stories = pd.concat([story_1, story_2, story_3, story_4, story_5, story_6, story_7,\\\n",
    "                  story_8, story_9, story_10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac067783",
   "metadata": {},
   "source": [
    "## Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c5207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a csv file with the dataset to not run the APIs again. \n",
    "all_stories.to_csv('top_10_stories.csv')\n",
    "all_stories = pd.read_csv('top_10_stories.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65c871e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In college I met a girl at a house party. We d...</td>\n",
       "      <td>2023-09-30 00:25:52</td>\n",
       "      <td>37468</td>\n",
       "      <td>stories</td>\n",
       "      <td>CardiffGiant1212</td>\n",
       "      <td>submission</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dude, I hate to break it to you but as soon as...</td>\n",
       "      <td>2023-09-30 01:34:12</td>\n",
       "      <td>1779</td>\n",
       "      <td>stories</td>\n",
       "      <td>stpg1222</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coward</td>\n",
       "      <td>2023-09-30 00:38:37</td>\n",
       "      <td>1226</td>\n",
       "      <td>stories</td>\n",
       "      <td>Tall-Remote3112</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lmao I asked my husband what he would do if th...</td>\n",
       "      <td>2023-09-30 02:13:34</td>\n",
       "      <td>1055</td>\n",
       "      <td>stories</td>\n",
       "      <td>Jilltro</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everyone knows the order is drinking, talking,...</td>\n",
       "      <td>2023-09-30 01:24:44</td>\n",
       "      <td>715</td>\n",
       "      <td>stories</td>\n",
       "      <td>oldmanartie</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             datetime  \\\n",
       "0  In college I met a girl at a house party. We d...  2023-09-30 00:25:52   \n",
       "1  Dude, I hate to break it to you but as soon as...  2023-09-30 01:34:12   \n",
       "2                                             Coward  2023-09-30 00:38:37   \n",
       "3  Lmao I asked my husband what he would do if th...  2023-09-30 02:13:34   \n",
       "4  Everyone knows the order is drinking, talking,...  2023-09-30 01:24:44   \n",
       "\n",
       "   score subreddit          redditor        type  \\\n",
       "0  37468   stories  CardiffGiant1212  submission   \n",
       "1   1779   stories          stpg1222     comment   \n",
       "2   1226   stories   Tall-Remote3112     comment   \n",
       "3   1055   stories           Jilltro     comment   \n",
       "4    715   stories       oldmanartie     comment   \n",
       "\n",
       "                                               title  \n",
       "0  I thought she took me to the restroom to have ...  \n",
       "1  I thought she took me to the restroom to have ...  \n",
       "2  I thought she took me to the restroom to have ...  \n",
       "3  I thought she took me to the restroom to have ...  \n",
       "4  I thought she took me to the restroom to have ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a2671",
   "metadata": {},
   "source": [
    "## Datasets \n",
    "I decided to create two datasets, one only with the stories posted, one with the comments. This is to be able to analyse them separately. For instance, I could explore the emotional dimensions the stories have, and whether they provoke similar, or different emotions to the readers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14343b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dude, I hate to break it to you but as soon as...</td>\n",
       "      <td>2023-09-30 01:34:12</td>\n",
       "      <td>1779</td>\n",
       "      <td>stories</td>\n",
       "      <td>stpg1222</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coward</td>\n",
       "      <td>2023-09-30 00:38:37</td>\n",
       "      <td>1226</td>\n",
       "      <td>stories</td>\n",
       "      <td>Tall-Remote3112</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lmao I asked my husband what he would do if th...</td>\n",
       "      <td>2023-09-30 02:13:34</td>\n",
       "      <td>1055</td>\n",
       "      <td>stories</td>\n",
       "      <td>Jilltro</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everyone knows the order is drinking, talking,...</td>\n",
       "      <td>2023-09-30 01:24:44</td>\n",
       "      <td>715</td>\n",
       "      <td>stories</td>\n",
       "      <td>oldmanartie</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This reminds me of college when my roommates g...</td>\n",
       "      <td>2023-09-30 02:19:20</td>\n",
       "      <td>541</td>\n",
       "      <td>stories</td>\n",
       "      <td>talon2525</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             datetime  \\\n",
       "0  Dude, I hate to break it to you but as soon as...  2023-09-30 01:34:12   \n",
       "1                                             Coward  2023-09-30 00:38:37   \n",
       "2  Lmao I asked my husband what he would do if th...  2023-09-30 02:13:34   \n",
       "3  Everyone knows the order is drinking, talking,...  2023-09-30 01:24:44   \n",
       "4  This reminds me of college when my roommates g...  2023-09-30 02:19:20   \n",
       "\n",
       "   score subreddit         redditor     type  \\\n",
       "0   1779   stories         stpg1222  comment   \n",
       "1   1226   stories  Tall-Remote3112  comment   \n",
       "2   1055   stories          Jilltro  comment   \n",
       "3    715   stories      oldmanartie  comment   \n",
       "4    541   stories        talon2525  comment   \n",
       "\n",
       "                                               title  \n",
       "0  I thought she took me to the restroom to have ...  \n",
       "1  I thought she took me to the restroom to have ...  \n",
       "2  I thought she took me to the restroom to have ...  \n",
       "3  I thought she took me to the restroom to have ...  \n",
       "4  I thought she took me to the restroom to have ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame only with the comments \n",
    "df_comments = all_stories[all_stories['type'] == 'comment']\n",
    "df_comments.reset_index(drop=True, inplace=True)\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c330764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In college I met a girl at a house party. We d...</td>\n",
       "      <td>2023-09-30 00:25:52</td>\n",
       "      <td>37468</td>\n",
       "      <td>stories</td>\n",
       "      <td>CardiffGiant1212</td>\n",
       "      <td>submission</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, a couple of weeks ago I found out that m...</td>\n",
       "      <td>2023-08-23 05:12:17</td>\n",
       "      <td>15814</td>\n",
       "      <td>stories</td>\n",
       "      <td>OkDot3924</td>\n",
       "      <td>submission</td>\n",
       "      <td>I(32M) am divorcing my wife (33F) after findin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My 28 year old sister gave birth to her first ...</td>\n",
       "      <td>2023-08-25 16:44:06</td>\n",
       "      <td>14396</td>\n",
       "      <td>stories</td>\n",
       "      <td>dearSisterLove</td>\n",
       "      <td>submission</td>\n",
       "      <td>My sister died during post-partum and I'm a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me and my girlfriend,(both 26) have been datin...</td>\n",
       "      <td>2023-08-16 09:54:26</td>\n",
       "      <td>12598</td>\n",
       "      <td>stories</td>\n",
       "      <td>Then-Tale3612</td>\n",
       "      <td>submission</td>\n",
       "      <td>I surprised my girlfriend with Taylor swift ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WARNING! don't read this if you have any probl...</td>\n",
       "      <td>2023-09-10 14:07:01</td>\n",
       "      <td>11581</td>\n",
       "      <td>stories</td>\n",
       "      <td>missemusepigen</td>\n",
       "      <td>submission</td>\n",
       "      <td>I \"accidentally\" shit the bed in front of my b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My(25m) girlfriend(26) confessed to cheating o...</td>\n",
       "      <td>2023-12-07 23:29:30</td>\n",
       "      <td>10885</td>\n",
       "      <td>stories</td>\n",
       "      <td>disheveledhalfwit</td>\n",
       "      <td>submission</td>\n",
       "      <td>My girlfriend confessed to cheating on me so I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When my daughter was 5 years old, and just sta...</td>\n",
       "      <td>2023-10-26 02:29:16</td>\n",
       "      <td>10313</td>\n",
       "      <td>stories</td>\n",
       "      <td>itsathrowaway6877</td>\n",
       "      <td>submission</td>\n",
       "      <td>A quick story about my dating policy for my da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Four days ago I was walking with a coworker on...</td>\n",
       "      <td>2023-09-22 20:21:09</td>\n",
       "      <td>10136</td>\n",
       "      <td>stories</td>\n",
       "      <td>Sheeitsheeit</td>\n",
       "      <td>submission</td>\n",
       "      <td>Four days ago my coworker who's also my friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Edit: Reading through the comments made me rea...</td>\n",
       "      <td>2023-11-25 00:56:13</td>\n",
       "      <td>9477</td>\n",
       "      <td>stories</td>\n",
       "      <td>Suspicious-Group-418</td>\n",
       "      <td>submission</td>\n",
       "      <td>My boyfriend turned me bi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hi, I'm a 35 year old woman married to a 45 ye...</td>\n",
       "      <td>2023-08-03 10:50:11</td>\n",
       "      <td>9377</td>\n",
       "      <td>stories</td>\n",
       "      <td>Witty-Firefighter-28</td>\n",
       "      <td>submission</td>\n",
       "      <td>Husband wants to reset his whole life.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             datetime  \\\n",
       "0  In college I met a girl at a house party. We d...  2023-09-30 00:25:52   \n",
       "1  Well, a couple of weeks ago I found out that m...  2023-08-23 05:12:17   \n",
       "2  My 28 year old sister gave birth to her first ...  2023-08-25 16:44:06   \n",
       "3  me and my girlfriend,(both 26) have been datin...  2023-08-16 09:54:26   \n",
       "4  WARNING! don't read this if you have any probl...  2023-09-10 14:07:01   \n",
       "5  My(25m) girlfriend(26) confessed to cheating o...  2023-12-07 23:29:30   \n",
       "6  When my daughter was 5 years old, and just sta...  2023-10-26 02:29:16   \n",
       "7  Four days ago I was walking with a coworker on...  2023-09-22 20:21:09   \n",
       "8  Edit: Reading through the comments made me rea...  2023-11-25 00:56:13   \n",
       "9  Hi, I'm a 35 year old woman married to a 45 ye...  2023-08-03 10:50:11   \n",
       "\n",
       "   score subreddit              redditor        type  \\\n",
       "0  37468   stories      CardiffGiant1212  submission   \n",
       "1  15814   stories             OkDot3924  submission   \n",
       "2  14396   stories        dearSisterLove  submission   \n",
       "3  12598   stories         Then-Tale3612  submission   \n",
       "4  11581   stories        missemusepigen  submission   \n",
       "5  10885   stories     disheveledhalfwit  submission   \n",
       "6  10313   stories     itsathrowaway6877  submission   \n",
       "7  10136   stories          Sheeitsheeit  submission   \n",
       "8   9477   stories  Suspicious-Group-418  submission   \n",
       "9   9377   stories  Witty-Firefighter-28  submission   \n",
       "\n",
       "                                               title  \n",
       "0  I thought she took me to the restroom to have ...  \n",
       "1  I(32M) am divorcing my wife (33F) after findin...  \n",
       "2  My sister died during post-partum and I'm a co...  \n",
       "3  I surprised my girlfriend with Taylor swift ti...  \n",
       "4  I \"accidentally\" shit the bed in front of my b...  \n",
       "5  My girlfriend confessed to cheating on me so I...  \n",
       "6  A quick story about my dating policy for my da...  \n",
       "7  Four days ago my coworker who's also my friend...  \n",
       "8                          My boyfriend turned me bi  \n",
       "9             Husband wants to reset his whole life.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separating the posts from the comments \n",
    "df_posts = all_stories[all_stories['type'] == 'submission'].reset_index(drop=True)\n",
    "df_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4342740",
   "metadata": {},
   "source": [
    "## Tokens and Lemmas\n",
    "Tokenisation converts texts into individual words, and lemmatising converts them into their base  (Educative, 2024) E.g. Mice to mouse. These are functions within an NLP library - NLKT (Natural Language Toolkit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac66a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatise and tokenise function\n",
    "def lemma(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens if i.lower() not in stops and i.lower() not in punct]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2884a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spider', 'dog', 'mouse']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking it works \n",
    "lemma('The Spiders, dog and mice.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d40b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying lemma function to both dataframes \n",
    "df_posts.loc[:, 'text_lemmatised'] = df_posts['text'].apply(lemma)\n",
    "df_comments.loc[:, 'text_lemmatised'] = df_comments['text'].apply(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863f209",
   "metadata": {},
   "source": [
    "I applied the 'lemma' function as a separate column in both dataframes as I want to have access to the original text, in case this is of any use. Though this is still unclear. \n",
    "\n",
    "## VAD Dataset \n",
    "VAD is a model of emotions. It quantifies individual words with a specific value on three dimensions: valence, arousal and dominance. These define positivity and negativity, excitement and relaxation, and feeling in control or without it, respectively (Jones, Libert and Tynski, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e57c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the VAD scores to the datasets \n",
    "vad_scores_posts = []\n",
    "\n",
    "for lemmas in df_posts['text_lemmatised']:\n",
    "    vad_words = []\n",
    "    try:\n",
    "        for word in lemmas:\n",
    "            if word.lower() in vad.index:\n",
    "                vad_words.append(word.lower())\n",
    "        vad_ = vad.loc[vad_words]\n",
    "        vad_scores_posts.append(vad_.mean())\n",
    "    except:\n",
    "        vad_scores_posts.append(pd.Series([np.nan for _ in range(3)]))\n",
    "\n",
    "#DataFrame from vad_scores_posts\n",
    "vad_scores_posts_df = pd.DataFrame(vad_scores_posts, columns=['valence', 'arousal', 'dominance'])\n",
    "\n",
    "#Concatenate vad_scores_posts_df with the original 'df_posts' dataframe\n",
    "df_posts = pd.concat([df_posts, vad_scores_posts_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf292da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_scores_comments = []\n",
    "\n",
    "for lemmas in df_comments['text_lemmatised']:\n",
    "    vad_words = []\n",
    "    try:\n",
    "        for word in lemmas:\n",
    "            if word.lower() in vad.index:\n",
    "                vad_words.append(word.lower())\n",
    "        vad_ = vad.loc[vad_words]\n",
    "        vad_scores_comments.append(vad_.mean())\n",
    "    except:\n",
    "        vad_scores_comments.append(pd.Series([np.nan for _ in range(3)]))\n",
    "\n",
    "#DataFrame from vad_scores_comments\n",
    "vad_scores_comments_df = pd.DataFrame(vad_scores_comments, columns=['valence', 'arousal', 'dominance'])\n",
    "\n",
    "#Concatenate vad_scores_comments_df with the original 'df_comments' dataframe\n",
    "df_comments = pd.concat([df_comments, vad_scores_comments_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802d3b6",
   "metadata": {},
   "source": [
    "The datasets are ready. However, I will save them in the folder to access them easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ee1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.to_csv('comments.csv')\n",
    "df_comments = pd.read_csv('comments.csv', index_col = 0)\n",
    "df_posts.to_csv('posts.csv')\n",
    "df_posts = pd.read_csv('posts.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62ef45d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In college I met a girl at a house party. We d...</td>\n",
       "      <td>2023-09-30 00:25:52</td>\n",
       "      <td>37468</td>\n",
       "      <td>stories</td>\n",
       "      <td>CardiffGiant1212</td>\n",
       "      <td>submission</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['college', 'met', 'girl', 'house', 'party', '...</td>\n",
       "      <td>0.619743</td>\n",
       "      <td>0.496730</td>\n",
       "      <td>0.611576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, a couple of weeks ago I found out that m...</td>\n",
       "      <td>2023-08-23 05:12:17</td>\n",
       "      <td>15814</td>\n",
       "      <td>stories</td>\n",
       "      <td>OkDot3924</td>\n",
       "      <td>submission</td>\n",
       "      <td>I(32M) am divorcing my wife (33F) after findin...</td>\n",
       "      <td>['well', 'couple', 'week', 'ago', 'found', 'wi...</td>\n",
       "      <td>0.593527</td>\n",
       "      <td>0.510437</td>\n",
       "      <td>0.558512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My 28 year old sister gave birth to her first ...</td>\n",
       "      <td>2023-08-25 16:44:06</td>\n",
       "      <td>14396</td>\n",
       "      <td>stories</td>\n",
       "      <td>dearSisterLove</td>\n",
       "      <td>submission</td>\n",
       "      <td>My sister died during post-partum and I'm a co...</td>\n",
       "      <td>['28', 'year', 'old', 'sister', 'gave', 'birth...</td>\n",
       "      <td>0.579823</td>\n",
       "      <td>0.509153</td>\n",
       "      <td>0.529868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me and my girlfriend,(both 26) have been datin...</td>\n",
       "      <td>2023-08-16 09:54:26</td>\n",
       "      <td>12598</td>\n",
       "      <td>stories</td>\n",
       "      <td>Then-Tale3612</td>\n",
       "      <td>submission</td>\n",
       "      <td>I surprised my girlfriend with Taylor swift ti...</td>\n",
       "      <td>['girlfriend', '26', 'dating', 'three', 'year'...</td>\n",
       "      <td>0.676503</td>\n",
       "      <td>0.532078</td>\n",
       "      <td>0.610264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WARNING! don't read this if you have any probl...</td>\n",
       "      <td>2023-09-10 14:07:01</td>\n",
       "      <td>11581</td>\n",
       "      <td>stories</td>\n",
       "      <td>missemusepigen</td>\n",
       "      <td>submission</td>\n",
       "      <td>I \"accidentally\" shit the bed in front of my b...</td>\n",
       "      <td>['warning', \"n't\", 'read', 'problem', 'feces',...</td>\n",
       "      <td>0.611488</td>\n",
       "      <td>0.518045</td>\n",
       "      <td>0.593588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             datetime  \\\n",
       "0  In college I met a girl at a house party. We d...  2023-09-30 00:25:52   \n",
       "1  Well, a couple of weeks ago I found out that m...  2023-08-23 05:12:17   \n",
       "2  My 28 year old sister gave birth to her first ...  2023-08-25 16:44:06   \n",
       "3  me and my girlfriend,(both 26) have been datin...  2023-08-16 09:54:26   \n",
       "4  WARNING! don't read this if you have any probl...  2023-09-10 14:07:01   \n",
       "\n",
       "   score subreddit          redditor        type  \\\n",
       "0  37468   stories  CardiffGiant1212  submission   \n",
       "1  15814   stories         OkDot3924  submission   \n",
       "2  14396   stories    dearSisterLove  submission   \n",
       "3  12598   stories     Then-Tale3612  submission   \n",
       "4  11581   stories    missemusepigen  submission   \n",
       "\n",
       "                                               title  \\\n",
       "0  I thought she took me to the restroom to have ...   \n",
       "1  I(32M) am divorcing my wife (33F) after findin...   \n",
       "2  My sister died during post-partum and I'm a co...   \n",
       "3  I surprised my girlfriend with Taylor swift ti...   \n",
       "4  I \"accidentally\" shit the bed in front of my b...   \n",
       "\n",
       "                                     text_lemmatised   valence   arousal  \\\n",
       "0  ['college', 'met', 'girl', 'house', 'party', '...  0.619743  0.496730   \n",
       "1  ['well', 'couple', 'week', 'ago', 'found', 'wi...  0.593527  0.510437   \n",
       "2  ['28', 'year', 'old', 'sister', 'gave', 'birth...  0.579823  0.509153   \n",
       "3  ['girlfriend', '26', 'dating', 'three', 'year'...  0.676503  0.532078   \n",
       "4  ['warning', \"n't\", 'read', 'problem', 'feces',...  0.611488  0.518045   \n",
       "\n",
       "   dominance  \n",
       "0   0.611576  \n",
       "1   0.558512  \n",
       "2   0.529868  \n",
       "3   0.610264  \n",
       "4   0.593588  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e5675e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>redditor</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dude, I hate to break it to you but as soon as...</td>\n",
       "      <td>2023-09-30 01:34:12</td>\n",
       "      <td>1779</td>\n",
       "      <td>stories</td>\n",
       "      <td>stpg1222</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['dude', 'hate', 'break', 'soon', 'farted', 'f...</td>\n",
       "      <td>0.543494</td>\n",
       "      <td>0.640114</td>\n",
       "      <td>0.529571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coward</td>\n",
       "      <td>2023-09-30 00:38:37</td>\n",
       "      <td>1226</td>\n",
       "      <td>stories</td>\n",
       "      <td>Tall-Remote3112</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['coward']</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>0.387136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lmao I asked my husband what he would do if th...</td>\n",
       "      <td>2023-09-30 02:13:34</td>\n",
       "      <td>1055</td>\n",
       "      <td>stories</td>\n",
       "      <td>Jilltro</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['lmao', 'asked', 'husband', 'would', 'happene...</td>\n",
       "      <td>0.548481</td>\n",
       "      <td>0.481526</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everyone knows the order is drinking, talking,...</td>\n",
       "      <td>2023-09-30 01:24:44</td>\n",
       "      <td>715</td>\n",
       "      <td>stories</td>\n",
       "      <td>oldmanartie</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['everyone', 'know', 'order', 'drinking', 'tal...</td>\n",
       "      <td>0.671437</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.617617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This reminds me of college when my roommates g...</td>\n",
       "      <td>2023-09-30 02:19:20</td>\n",
       "      <td>541</td>\n",
       "      <td>stories</td>\n",
       "      <td>talon2525</td>\n",
       "      <td>comment</td>\n",
       "      <td>I thought she took me to the restroom to have ...</td>\n",
       "      <td>['reminds', 'college', 'roommate', 'gf', 'came...</td>\n",
       "      <td>0.613123</td>\n",
       "      <td>0.491981</td>\n",
       "      <td>0.567193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             datetime  \\\n",
       "0  Dude, I hate to break it to you but as soon as...  2023-09-30 01:34:12   \n",
       "1                                             Coward  2023-09-30 00:38:37   \n",
       "2  Lmao I asked my husband what he would do if th...  2023-09-30 02:13:34   \n",
       "3  Everyone knows the order is drinking, talking,...  2023-09-30 01:24:44   \n",
       "4  This reminds me of college when my roommates g...  2023-09-30 02:19:20   \n",
       "\n",
       "   score subreddit         redditor     type  \\\n",
       "0   1779   stories         stpg1222  comment   \n",
       "1   1226   stories  Tall-Remote3112  comment   \n",
       "2   1055   stories          Jilltro  comment   \n",
       "3    715   stories      oldmanartie  comment   \n",
       "4    541   stories        talon2525  comment   \n",
       "\n",
       "                                               title  \\\n",
       "0  I thought she took me to the restroom to have ...   \n",
       "1  I thought she took me to the restroom to have ...   \n",
       "2  I thought she took me to the restroom to have ...   \n",
       "3  I thought she took me to the restroom to have ...   \n",
       "4  I thought she took me to the restroom to have ...   \n",
       "\n",
       "                                     text_lemmatised   valence   arousal  \\\n",
       "0  ['dude', 'hate', 'break', 'soon', 'farted', 'f...  0.543494  0.640114   \n",
       "1                                         ['coward']  0.289720  0.463122   \n",
       "2  ['lmao', 'asked', 'husband', 'would', 'happene...  0.548481  0.481526   \n",
       "3  ['everyone', 'know', 'order', 'drinking', 'tal...  0.671437  0.488964   \n",
       "4  ['reminds', 'college', 'roommate', 'gf', 'came...  0.613123  0.491981   \n",
       "\n",
       "   dominance  \n",
       "0   0.529571  \n",
       "1   0.387136  \n",
       "2   0.575000  \n",
       "3   0.617617  \n",
       "4   0.567193  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d19ae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "304c1e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23e837",
   "metadata": {},
   "source": [
    "## Limitations \n",
    "Whilst I hope that this corpus could bring some insights in storytelling, I am aware that only sourcing data from Reddit might not be representative of all ‘successful’ storytelling. More studies across different platforms would be needed to clarify that. Also, I must admit that the ‘df_stories; data frame might be too small to provide a good view on sentiment analysis trends, or narrative structures. \n",
    "\n",
    "Furthermore, to have a more holistic view on narratives and storytelling, less popular stories should be included in the corpus. However, Reddit imposes a big limitation, at least through APIs, as posts with downvotes or less comments are not easily accessible, meaning there isn’t an option to filter them. If I want to include them, I would have to source the data manually, which is time consuming and the collection would be subject to my own biases. \n",
    "\n",
    "### NLP Limitations\n",
    "Even if the limitations above were not present, it’s also worth mentioning that NLP in itself presents limitations, such as difficulties accessing APIs from more renowned social media platforms that could benefit the analysis, and loss in semantics through the applications of lemmas, tokens and VAD values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ecd72",
   "metadata": {},
   "source": [
    "------------\n",
    "#### This work contains 559 words. \n",
    "-------------\n",
    "\n",
    "#### Declarations\n",
    "I have used chat GPT to work on this assignment mainly to check the code was written in the right format, for instance, using using the correct brackets for indexing or applying functions. I did not copy a paste any code which was solely written by AI. I also checked my overall idea in storytelling, but I did not find this of much help. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39583a",
   "metadata": {},
   "source": [
    "# Bibliography \n",
    "    Educative (2024). Difference between tokenization and lemmatization in NLP. [online] Educative. Available at: https://www.educative.io/answers/difference-between-tokenization-and-lemmatization-in-nlp.Frye\n",
    "\n",
    "    M.-K. (2018). What is an API? (Application Programming Interface). [online] MuleSoft. Available at: https://www.mulesoft.com/resources/api/what-is-an-api.IBM \n",
    "    \n",
    "    (n.d.). What is Natural Language Processing? | IBM. [online] www.ibm.com. Available at: https://www.ibm.com/topics/natural-language-processing#:~:text=the%20next%20step-.Jones\n",
    "    \n",
    "    K., Libert, K. and Tynski, K. (2016). The Emotional Combinations That Make Stories Go Viral. [online] Harvard Business Review. Available at: https://hbr.org/2016/05/research-the-link-between-feeling-in-control-and-viral-content#:~:text=The%20findings%20indicate%20that%20individual.Joshi\n",
    "    \n",
    "    A.K. (1991). Natural Language Processing. Science, 253(5025), pp.1242–1249. doi:https://doi.org/10.1126/science.253.5025.1242.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
